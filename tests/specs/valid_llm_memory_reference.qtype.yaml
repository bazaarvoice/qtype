id: app_llm_memory_ref
models:
  - type: Model
    id: m1
    provider: openai
    model_id: gpt-4
    inference_params:
      temperature: 0.5
      max_tokens: 100
memories:
  - id: mem1
flows:
  - type: Flow
    id: f1
    steps:
      - id: llm1
        type: LLMInference
        model: m1
        memory: mem1
        system_message: hi
